{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WK03: Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This code imports the functions we need to run our inference pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Completion\n",
    "\n",
    "Let's use the GPT2 model to create some text completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_GEN_MODEL = \"openai-community/gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some phrases that we'll use as sentence starters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASE_EXAMPLES = [\n",
    "  \"How much wood would a woodchuck chuck if \",\n",
    "  \"I once knew a man from Natucket, who \",\n",
    "  \"To be or not to be, \"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a Transformers pipeline object to run inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=TEXT_GEN_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the generator on a starter phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator(\"To be or not to be, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ask for longer responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator(\"To be or not to be, \", max_length=100, pad_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Model\n",
    "\n",
    "is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_GEN_MODEL = \"Xenova/llama2.c-stories110M\"\n",
    "generator = pipeline(\"text-generation\", model=TEXT_GEN_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun with new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator(\"To be or not to be, \", max_length=32, pad_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_GEN_MODEL = \"facebook/opt-125m\"\n",
    "generator = pipeline(\"text-generation\", model=TEXT_GEN_MODEL)\n",
    "\n",
    "generator(\"To be or not to be, \", max_length=32, pad_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sentiment Analysis\n",
    "\n",
    "Define model and create some example phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_SENT_MODEL = \"joeddav/distilbert-base-uncased-go-emotions-student\"\n",
    "\n",
    "EXAMPLE_TEXTS = [\n",
    "  \"What a wonderful day\",\n",
    "  \"OMG my head hurts\",\n",
    "  \"What am I doing here?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inference pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = pipeline(\"sentiment-analysis\", model=TEXT_SENT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on example phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in EXAMPLE_TEXTS:\n",
    "  result = analyzer(t)\n",
    "  print(t, \"->\", result[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define our pipeline like this if we want to get scores for all possible sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_analyzer = pipeline(\"sentiment-analysis\", model=TEXT_SENT_MODEL, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in EXAMPLE_TEXTS:\n",
    "  result = full_analyzer(t)\n",
    "  sorted_result = sorted(result[0], key=lambda A: A[\"score\"], reverse=True)\n",
    "  top_3_labels = [s[\"label\"] for s in sorted_result[:3]]\n",
    "  print(t, \"->\", top_3_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New model definition/location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CAP_MODEL = \"Salesforce/blip-image-captioning-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = Image.open(\"./imgs/GDTM.jpg\").convert(\"RGB\")\n",
    "display(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_captioner = pipeline(task=\"image-to-text\", model=IMAGE_CAP_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = img_captioner(test_image)\n",
    "print(result[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other image description models:\n",
    "- [`LLAVA`](https://huggingface.co/llava-hf/llava-interleave-qwen-0.5b-hf)\n",
    "- [`VIT`](https://huggingface.co/nlpconnect/vit-gpt2-image-captioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next-Word Model\n",
    "\n",
    "or, a _fill-mask_ model, can be used to get the probabilities/scores of different possible words to complete a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_MODEL = \"FacebookAI/xlm-roberta-large\"\n",
    "unmasker = pipeline(\"fill-mask\", model=MASK_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker(\"To be or not to be that is the <mask>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
